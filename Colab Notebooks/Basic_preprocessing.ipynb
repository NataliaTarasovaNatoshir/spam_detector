{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Basic_preprocessing.ipynb","provenance":[],"collapsed_sections":["kFf-Bpym_9Ed"],"authorship_tag":"ABX9TyPDPR08+68xMvLg/KawcA6I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Preparations"],"metadata":{"id":"kFf-Bpym_9Ed"}},{"cell_type":"code","source":["import json\n","import os"],"metadata":{"id":"g2ZGCSwpAlGW","executionInfo":{"status":"ok","timestamp":1652542581214,"user_tz":-180,"elapsed":489,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## Mount Google Drive with raw data"],"metadata":{"id":"SWAi1lZNAFYv"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"alxBLc3a_7bj","executionInfo":{"status":"ok","timestamp":1652542584741,"user_tz":-180,"elapsed":3065,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}},"outputId":"c54529f6-363b-4ad7-880b-4293183024ed"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["! ls /content/drive/MyDrive/Colab\\ Notebooks/Spam_Detector/Enron_raw_data/dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0oENmooOlnpk","executionInfo":{"status":"ok","timestamp":1652542584742,"user_tz":-180,"elapsed":26,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}},"outputId":"d174ab4e-534e-41f3-a28c-f9be826121dc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["test  train  train.csv\n"]}]},{"cell_type":"markdown","source":["## Install this project package from github"],"metadata":{"id":"Nt3vlhEPAV76"}},{"cell_type":"code","source":["!rm -rf /content/spam_detector/\n","!git clone https://github.com/NataliaTarasovaNatoshir/spam_detector.git\n","%cd spam_detector/\n","!git pull origin master\n","!python setup.py install"],"metadata":{"id":"VbttZ7l9HvkM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652542587452,"user_tz":-180,"elapsed":2719,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}},"outputId":"db4528a1-2480-4a00-8869-d7969b96118c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'spam_detector'...\n","remote: Enumerating objects: 63, done.\u001b[K\n","remote: Counting objects: 100% (63/63), done.\u001b[K\n","remote: Compressing objects: 100% (48/48), done.\u001b[K\n","remote: Total 63 (delta 29), reused 47 (delta 13), pack-reused 0\u001b[K\n","Unpacking objects: 100% (63/63), done.\n","/content/spam_detector\n","From https://github.com/NataliaTarasovaNatoshir/spam_detector\n"," * branch            master     -> FETCH_HEAD\n","Already up to date.\n","/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:502: UserWarning: The version specified ('') is an invalid version, this may not work as expected with newer versions of setuptools, pip, and PyPI. Please see PEP 440 for more details.\n","  \"details.\" % version\n","running install\n","running bdist_egg\n","running egg_info\n","creating spam_detector.egg-info\n","writing spam_detector.egg-info/PKG-INFO\n","writing dependency_links to spam_detector.egg-info/dependency_links.txt\n","writing top-level names to spam_detector.egg-info/top_level.txt\n","writing manifest file 'spam_detector.egg-info/SOURCES.txt'\n","writing manifest file 'spam_detector.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build\n","creating build/lib\n","creating build/lib/spam_detector\n","copying spam_detector/__init__.py -> build/lib/spam_detector\n","copying spam_detector/raw_dataset_build.py -> build/lib/spam_detector\n","copying spam_detector/basic_preprocessing.py -> build/lib/spam_detector\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/spam_detector\n","copying build/lib/spam_detector/__init__.py -> build/bdist.linux-x86_64/egg/spam_detector\n","copying build/lib/spam_detector/raw_dataset_build.py -> build/bdist.linux-x86_64/egg/spam_detector\n","copying build/lib/spam_detector/basic_preprocessing.py -> build/bdist.linux-x86_64/egg/spam_detector\n","byte-compiling build/bdist.linux-x86_64/egg/spam_detector/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/spam_detector/raw_dataset_build.py to raw_dataset_build.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/spam_detector/basic_preprocessing.py to basic_preprocessing.cpython-37.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying spam_detector.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying spam_detector.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying spam_detector.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying spam_detector.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","creating dist\n","creating 'dist/spam_detector-0.0.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing spam_detector-0.0.0-py3.7.egg\n","Removing /usr/local/lib/python3.7/dist-packages/spam_detector-0.0.0-py3.7.egg\n","Copying spam_detector-0.0.0-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n","spam-detector 0.0.0 is already the active version in easy-install.pth\n","\n","Installed /usr/local/lib/python3.7/dist-packages/spam_detector-0.0.0-py3.7.egg\n","Processing dependencies for spam-detector==0.0.0\n","Finished processing dependencies for spam-detector==0.0.0\n"]}]},{"cell_type":"code","source":["# load config from package\n","with open(\"/content/spam_detector/spam_detector/config.json\") as file:\n","  config = json.load(file)\n","config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPUmmDuj57FG","executionInfo":{"status":"ok","timestamp":1652542587453,"user_tz":-180,"elapsed":29,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}},"outputId":"148e4516-f29d-42c3-f137-c6abcf124cd2"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'dataset_build': {'raw_files_folder': '/content/drive/MyDrive/Colab Notebooks/Spam_Detector/Enron_raw_data/raw_files',\n","  'res_dataset_folder_name': '/content/drive/MyDrive/Colab Notebooks/Spam_Detector/Enron_raw_data/dataset',\n","  'test_share': 0.3}}"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["# Overview"],"metadata":{"id":"LoS_QGbU51sd"}},{"cell_type":"code","source":["dataset_folder = config['dataset_build']['res_dataset_folder_name']"],"metadata":{"id":"AtiXlK8pGLmo","executionInfo":{"status":"ok","timestamp":1652542592315,"user_tz":-180,"elapsed":307,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["ham_test_cnt = len(os.listdir(os.path.join(dataset_folder, 'test', 'ham')))\n","spam_test_cnt = len(os.listdir(os.path.join(dataset_folder, 'test', 'spam')))\n","ham_train_cnt = len(os.listdir(os.path.join(dataset_folder, 'train', 'ham')))\n","spam_train_cnt = len(os.listdir(os.path.join(dataset_folder, 'train', 'spam')))\n","print('Resulting statistics')\n","print('Total number of files = {0}. Train: {1}, Test: {2} ({3:.0f}%)'.format(\n","    ham_test_cnt + spam_test_cnt + ham_train_cnt + spam_train_cnt, ham_train_cnt + spam_train_cnt,\n","    ham_test_cnt + spam_test_cnt,\n","    100 * (ham_test_cnt + spam_test_cnt) / (ham_test_cnt + spam_test_cnt + ham_train_cnt + spam_train_cnt)))\n","print(\"Train. Ham: {0}, Spam: {1} ({2:.0f}%)\".format(ham_train_cnt, spam_train_cnt,\n","                                                      100 * spam_train_cnt / (ham_train_cnt + spam_train_cnt)))\n","print(\"Test. Ham: {0}, Spam: {1} ({2:.0f}%)\".format(ham_test_cnt, spam_test_cnt,\n","                                                      100 * spam_test_cnt / (ham_test_cnt + spam_test_cnt)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5f0cyOjCPB7A","executionInfo":{"status":"ok","timestamp":1652542593764,"user_tz":-180,"elapsed":1051,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}},"outputId":"a7510ddd-dc4c-467d-99e3-235e5b20c415"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Resulting statistics\n","Total number of files = 33708. Train: 23599, Test: 10109 (30%)\n","Train. Ham: 11583, Spam: 12016 (51%)\n","Test. Ham: 4962, Spam: 5147 (51%)\n"]}]},{"cell_type":"markdown","source":["Let's look at random examples"],"metadata":{"id":"ym0En16q63zn"}},{"cell_type":"code","source":["# ham\n","ham_files = os.listdir(os.path.join(dataset_folder, 'train', 'ham'))\n","with open(os.path.join(os.path.join(dataset_folder, 'train', 'ham'), ham_files[5000]), 'r') as f:\n","  text = f.read()\n","text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120},"id":"NvaWSJJuyhoN","executionInfo":{"status":"ok","timestamp":1652542599194,"user_tz":-180,"elapsed":5437,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}},"outputId":"76857f45-82ff-48fb-e10a-78c1723cc5a4"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Subject: august palo verde\\nmy latest information on rate increases in california indicates that they will be implemented june lst . that means that customers don ' t see a price signal until june and won ' t actually see their bill until july . while i agree with greg that we may see dramatic demand side response once people see their bills , we have no idea how long it will take people and businesses to adjust their behavior . i don ' t really care what positions you guys want to carry . my only advice is that greg is short a fairly illiquid product . if you want to get out right now you would have to pay , at least for some of your position , north of $ 800 / mwh . in the near term i don ' t think that it will be easy to get out of this trade . in the long run , if the market comes off , it will be easy to get out .\\nbottom line - -\\nat the end of the day i think that you may be right , but things look very bullish right now . i want to make sure that you know that you have already pushed the bounds of liquidity for that product and that you should not expect us to provide liquidity to you in a market that doesn ' t offer it to us when it is time to get out .\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# spam\n","spam_files = os.listdir(os.path.join(dataset_folder, 'train', 'spam'))\n","with open(os.path.join(os.path.join(dataset_folder, 'train', 'spam'), spam_files[3000]), 'r') as f:\n","  text = f.read()\n","text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"FfjZ2DyOzBd-","executionInfo":{"status":"ok","timestamp":1652542599778,"user_tz":-180,"elapsed":606,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}},"outputId":"f7ea8d8e-9653-430d-a93b-ad946f27e652"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Subject: message subject\\ncentum situs syllabic bonnie decorticate petroglyph\\nfind all your medications in one place !\\na whole variety of pills ! have a look !\\nyou name it ! we have it !\\nstop receiving promotional material now\\ncoralline dactyl quicken combinatorial cybernetics\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["# Basic preprocessing"],"metadata":{"id":"yD-dJF780Atn"}},{"cell_type":"markdown","source":["Take a folder with files and convert it to a dataframe. Create message_id, extract subject from mail text and remove \\n from the message text"],"metadata":{"id":"aUcolhxM0fMo"}},{"cell_type":"code","source":["def preprocess_message_text(message_text):\n","  res = {'subject': None, 'text': None}\n","  lines = message_text.split('\\n')\n","  if lines[0][:len('Subject:')] == 'Subject:':\n","    res['subject'] = lines[0][len('Subject: '):]\n","    res['text'] = ' '.join(lines[1:])\n","  else:\n","    res['text'] = ' '.join(lines)\n","  return res"],"metadata":{"id":"aEZfpDq80Se-","executionInfo":{"status":"ok","timestamp":1652542604006,"user_tz":-180,"elapsed":311,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["preprocess_message_text(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"coWpd7Oo4V5F","executionInfo":{"status":"ok","timestamp":1652542604440,"user_tz":-180,"elapsed":16,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}},"outputId":"28e571cc-8a09-489d-f6b9-85dc4ec20984"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'subject': 'message subject',\n"," 'text': 'centum situs syllabic bonnie decorticate petroglyph find all your medications in one place ! a whole variety of pills ! have a look ! you name it ! we have it ! stop receiving promotional material now coralline dactyl quicken combinatorial cybernetics '}"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# test preprocessing on first 15 files in folder\n","import pandas as pd\n","def preprocess_mails_in_folder(folder_path):\n","  print('Processing files in folder {}'.format(folder_path))\n","  df = []\n","  all_files = os.listdir(folder_path)\n","  print('Number of files in folder: {}'.format(len(all_files)))\n","  processed_num = 0\n","  for file_name in all_files:\n","    if processed_num%100 == 0: print(\"{} files out of {}\".format(\n","        processed_num, len(all_files)))\n","    with open(os.path.join(folder_path, file_name), 'r') as f:\n","      text = f.read()\n","    preprocessed_text = preprocess_message_text(text)\n","    preprocessed_text['message_id'] = file_name\n","    df.append(preprocessed_text)\n","    processed_num += 1\n","    if processed_num == 15: break\n","  print('Preparing dataframe')\n","  df = pd.DataFrame(df)\n","  print('Processing completed')\n","  return df"],"metadata":{"id":"MzXnDD6v4f9D","executionInfo":{"status":"ok","timestamp":1652542604976,"user_tz":-180,"elapsed":547,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["df = preprocess_mails_in_folder(folder_path=os.path.join(dataset_folder, 'test', 'ham'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3OqwFB4W6Q-j","executionInfo":{"status":"ok","timestamp":1652542604979,"user_tz":-180,"elapsed":37,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}},"outputId":"ac4a5efe-adef-4415-b52e-948143df9f14"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing files in folder /content/drive/MyDrive/Colab Notebooks/Spam_Detector/Enron_raw_data/dataset/test/ham\n","Number of files in folder: 4962\n","0 files out of 4962\n","Preparing dataframe\n","Processing completed\n"]}]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"J6WfVlQc7pLQ","executionInfo":{"status":"ok","timestamp":1652542604983,"user_tz":-180,"elapsed":34,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}},"outputId":"1135f593-4c88-4883-fbd9-5e32d079881d"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              subject  \\\n","0                                        prc for todd   \n","1                                        var training   \n","2             average eol and non - eol deals per day   \n","3                                     ena sap project   \n","4                                   re : var training   \n","5                           enron japan weekly update   \n","6                       sap id - here it is ! ! ! ! !   \n","7   for discussion : implementing definition of tr...   \n","8                 conference call text for discussion   \n","9                                2000 accomplishments   \n","10                               2000 accomplishments   \n","11  june 3 , 2000 super saturday results and assig...   \n","12                                 equity adjustments   \n","13                        re : var for credit trading   \n","14                    may curve validation memorandum   \n","\n","                                                 text  \\\n","0   sally , attached below is a list of my accompl...   \n","1   sally , angela sprock forwarded your vm to me ...   \n","2   fyi - we are now distributing the \" john lavor...   \n","3   as you know , we have substantially wrapped up...   \n","4   sally , i understand your comments . i ' ll ge...   \n","5   hello ejot , this is just a reminder about thu...   \n","6   the following sap id and password allows you t...   \n","7   this is the memo i was referring to - - - - - ...   \n","8   - - - - - - - - - - - - - - - - - - - - - - fo...   \n","9   sap related - - financial settlements develope...   \n","10  sap related - - financial settlements develope...   \n","11  attached are the super saturday results ( offe...   \n","12  sally , i reviewed the salaries of my team wit...   \n","13  ted thanks for the note - coming from jpmorgan...   \n","14  attached is may ' s curve validation memorandu...   \n","\n","                      message_id  \n","0   1496.2000-06-18.beck.ham.txt  \n","1   1516.2000-06-19.beck.ham.txt  \n","2   1518.2000-06-19.beck.ham.txt  \n","3   1546.2000-06-20.beck.ham.txt  \n","4   1551.2000-06-20.beck.ham.txt  \n","5   1556.2000-06-21.beck.ham.txt  \n","6   1562.2000-06-21.beck.ham.txt  \n","7   1573.2000-06-21.beck.ham.txt  \n","8   1576.2000-06-21.beck.ham.txt  \n","9   1604.2000-06-23.beck.ham.txt  \n","10  1608.2000-06-23.beck.ham.txt  \n","11  1616.2000-06-23.beck.ham.txt  \n","12  1619.2000-06-23.beck.ham.txt  \n","13  1638.2000-06-26.beck.ham.txt  \n","14  1651.2000-06-26.beck.ham.txt  "],"text/html":["\n","  <div id=\"df-9b1e35d0-65e6-4190-a976-d3c5fb6ecf2d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>subject</th>\n","      <th>text</th>\n","      <th>message_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>prc for todd</td>\n","      <td>sally , attached below is a list of my accompl...</td>\n","      <td>1496.2000-06-18.beck.ham.txt</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>var training</td>\n","      <td>sally , angela sprock forwarded your vm to me ...</td>\n","      <td>1516.2000-06-19.beck.ham.txt</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>average eol and non - eol deals per day</td>\n","      <td>fyi - we are now distributing the \" john lavor...</td>\n","      <td>1518.2000-06-19.beck.ham.txt</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ena sap project</td>\n","      <td>as you know , we have substantially wrapped up...</td>\n","      <td>1546.2000-06-20.beck.ham.txt</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>re : var training</td>\n","      <td>sally , i understand your comments . i ' ll ge...</td>\n","      <td>1551.2000-06-20.beck.ham.txt</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>enron japan weekly update</td>\n","      <td>hello ejot , this is just a reminder about thu...</td>\n","      <td>1556.2000-06-21.beck.ham.txt</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>sap id - here it is ! ! ! ! !</td>\n","      <td>the following sap id and password allows you t...</td>\n","      <td>1562.2000-06-21.beck.ham.txt</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>for discussion : implementing definition of tr...</td>\n","      <td>this is the memo i was referring to - - - - - ...</td>\n","      <td>1573.2000-06-21.beck.ham.txt</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>conference call text for discussion</td>\n","      <td>- - - - - - - - - - - - - - - - - - - - - - fo...</td>\n","      <td>1576.2000-06-21.beck.ham.txt</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2000 accomplishments</td>\n","      <td>sap related - - financial settlements develope...</td>\n","      <td>1604.2000-06-23.beck.ham.txt</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2000 accomplishments</td>\n","      <td>sap related - - financial settlements develope...</td>\n","      <td>1608.2000-06-23.beck.ham.txt</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>june 3 , 2000 super saturday results and assig...</td>\n","      <td>attached are the super saturday results ( offe...</td>\n","      <td>1616.2000-06-23.beck.ham.txt</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>equity adjustments</td>\n","      <td>sally , i reviewed the salaries of my team wit...</td>\n","      <td>1619.2000-06-23.beck.ham.txt</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>re : var for credit trading</td>\n","      <td>ted thanks for the note - coming from jpmorgan...</td>\n","      <td>1638.2000-06-26.beck.ham.txt</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>may curve validation memorandum</td>\n","      <td>attached is may ' s curve validation memorandu...</td>\n","      <td>1651.2000-06-26.beck.ham.txt</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b1e35d0-65e6-4190-a976-d3c5fb6ecf2d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9b1e35d0-65e6-4190-a976-d3c5fb6ecf2d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9b1e35d0-65e6-4190-a976-d3c5fb6ecf2d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# Preprocess train and test datasets and save to csv"],"metadata":{"id":"JvzyN99-89zW"}},{"cell_type":"code","source":["from spam_detector import basic_preprocessing"],"metadata":{"id":"nzXRDjyNNzbn","executionInfo":{"status":"ok","timestamp":1652542622163,"user_tz":-180,"elapsed":300,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Build a dataframe with training data\n","\n","df_ham = basic_preprocessing.preprocess_mails_in_folder(folder_path=os.path.join(dataset_folder, 'train', 'ham'))\n","df_ham['label'] = 0\n","print()\n","\n","df_spam = basic_preprocessing.preprocess_mails_in_folder(folder_path=os.path.join(dataset_folder, 'train', 'spam'))\n","df_spam['label'] = 1\n","\n","df = pd.concat([df_ham, df_spam], ignore_index=True)\n","df.to_csv(os.path.join(dataset_folder, 'train.csv'), index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZsaB_tkX8i0u","executionInfo":{"status":"ok","timestamp":1652542007167,"user_tz":-180,"elapsed":45099,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}},"outputId":"7d8c4ebb-6fa2-4566-f20a-85bf8f1a786f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing files in folder /content/drive/MyDrive/Colab Notebooks/Spam_Detector/Enron_raw_data/dataset/train/ham\n","Number of files in folder: 11583\n","0 files out of 11583\n","1000 files out of 11583\n","2000 files out of 11583\n","3000 files out of 11583\n","4000 files out of 11583\n","5000 files out of 11583\n","6000 files out of 11583\n","7000 files out of 11583\n","8000 files out of 11583\n","9000 files out of 11583\n","10000 files out of 11583\n","11000 files out of 11583\n","Preparing dataframe\n","Processing completed\n","\n","Processing files in folder /content/drive/MyDrive/Colab Notebooks/Spam_Detector/Enron_raw_data/dataset/train/spam\n","Number of files in folder: 12016\n","0 files out of 12016\n","1000 files out of 12016\n","2000 files out of 12016\n","Processing error: 4210.2005-04-03.BG.spam.txt\n","Processing error: 2067.2004-12-12.BG.spam.txt\n","Processing error: 2180.2004-12-18.BG.spam.txt\n","3000 files out of 12016\n","Processing error: 2381.2004-12-28.BG.spam.txt\n","4000 files out of 12016\n","5000 files out of 12016\n","6000 files out of 12016\n","Processing error: 4102.2005-01-31.GP.spam.txt\n","Processing error: 4522.2005-03-03.GP.spam.txt\n","7000 files out of 12016\n","Processing error: 5613.2005-07-10.GP.spam.txt\n","Processing error: 5687.2005-07-22.GP.spam.txt\n","8000 files out of 12016\n","Processing error: 1474.2004-06-16.GP.spam.txt\n","9000 files out of 12016\n","10000 files out of 12016\n","11000 files out of 12016\n","Processing error: 2526.2004-10-17.GP.spam.txt\n","Processing error: 2698.2004-10-31.GP.spam.txt\n","12000 files out of 12016\n","Preparing dataframe\n","Processing completed\n"]}]},{"cell_type":"code","source":["# Build a dataframe with testing data\n","\n","df_ham = basic_preprocessing.preprocess_mails_in_folder(folder_path=os.path.join(dataset_folder, 'test', 'ham'))\n","df_ham['label'] = 0\n","df_spam = basic_preprocessing.preprocess_mails_in_folder(folder_path=os.path.join(dataset_folder, 'test', 'spam'))\n","df_spam['label'] = 1\n","\n","df = pd.concat([df_ham, df_spam], ignore_index=True)\n","df.to_csv(os.path.join(dataset_folder, 'test.csv'), index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3J8ymCOEAHKw","executionInfo":{"status":"ok","timestamp":1652542716303,"user_tz":-180,"elapsed":89366,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}},"outputId":"b2937956-4c9f-4117-b035-9fda5dda6424"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing files in folder /content/drive/MyDrive/Colab Notebooks/Spam_Detector/Enron_raw_data/dataset/test/ham\n","Number of files in folder: 4962\n","0 files out of 4962\n","1000 files out of 4962\n","2000 files out of 4962\n","3000 files out of 4962\n","4000 files out of 4962\n","Preparing dataframe\n","Processing completed\n","Processing files in folder /content/drive/MyDrive/Colab Notebooks/Spam_Detector/Enron_raw_data/dataset/test/spam\n","Number of files in folder: 5147\n","0 files out of 5147\n","1000 files out of 5147\n","2000 files out of 5147\n","Processing error: 5268.2005-05-24.GP.spam.txt\n","3000 files out of 5147\n","4000 files out of 5147\n","Processing error: 4566.2005-05-24.GP.spam.txt\n","Processing error: 1938.2004-12-19.BG.spam.txt\n","5000 files out of 5147\n","Processing error: 2248.2004-09-23.GP.spam.txt\n","Preparing dataframe\n","Processing completed\n"]}]},{"cell_type":"code","source":["# ensure all changes are saved on google drive\n","drive.flush_and_unmount()\n","print('All changes made in this colab session should now be visible in Drive.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wALmDAYmAYvz","executionInfo":{"status":"ok","timestamp":1652542744935,"user_tz":-180,"elapsed":1998,"user":{"displayName":"Наталья Тарасова","userId":"09105063837501789488"}},"outputId":"b2a71e88-31ae-4792-de43-23be9b6a0516"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["All changes made in this colab session should now be visible in Drive.\n"]}]}]}